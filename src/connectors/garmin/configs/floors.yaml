# =============================================================================
# GARMIN FLOORS - ARRAY EXPANSION FORMAT
# =============================================================================
# This dataset uses array expansion to transform time-series arrays into records
# Each element of floorValuesArray becomes an individual BigQuery record
#
# Format source:
# {
#   "floorValuesArray": [
#     ["2025-10-27T08:15:00.0", "2025-10-27T08:30:00.0", 6, 0],
#     ...
#   ],
#   "floorsValueDescriptorDTOList": [
#     {"key": "startTimeGMT", "index": 0},
#     {"key": "endTimeGMT", "index": 1},
#     {"key": "floorsAscended", "index": 2},
#     {"key": "floorsDescended", "index": 3}
#   ]
# }
#
# Result: 96 records per day (15-minute intervals)
# =============================================================================

data_type: floors
description: "Garmin floors climbed/descended data (15-minute intervals)"
version: "2.0.0"
owner: "data-platform"
last_updated: "2025-10-31"

# =============================================================================
# SOURCE CONFIGURATION
# =============================================================================
source:
  bucket_pattern: "ela-dp-{env}"
  landing_path: "garmin/landing"
  file_pattern: "*_floors.jsonl"
  archive_path: "garmin/archive"
  rejected_path: "garmin/rejected"
  delete_after_archive: false
  max_file_age_days: 30

# =============================================================================
# DESTINATION CONFIGURATION
# =============================================================================
destination:
  project_id: "${GCP_PROJECT_ID}"
  dataset_pattern: "dp_lake_{env}"
  table_name: "lake_garmin__normalized_floors"
  write_disposition: "WRITE_APPEND"
  create_disposition: "CREATE_IF_NEEDED"

  partition:
    enabled: true
    field: "dp_inserted_at"
    type: "DAY"
    expiration_days: null

  clustering:
    enabled: true
    fields:
      - "calendarDate"

# =============================================================================
# PARSING CONFIGURATION
# =============================================================================
parsing:
  strategy: "hybrid"

  core_fields:
    - name: startTimestampGMT
      json_path: "$.startTimestampGMT"
      bq_type: TIMESTAMP
      mode: NULLABLE
      description: "Day start timestamp (GMT)"
      transform: "string_to_timestamp"

    - name: endTimestampGMT
      json_path: "$.endTimestampGMT"
      bq_type: TIMESTAMP
      mode: NULLABLE
      description: "Day end timestamp (GMT)"
      transform: "string_to_timestamp"

    - name: startTimestampLocal
      json_path: "$.startTimestampLocal"
      bq_type: TIMESTAMP
      mode: NULLABLE
      description: "Day start timestamp (Local)"
      transform: "string_to_timestamp"

    - name: endTimestampLocal
      json_path: "$.endTimestampLocal"
      bq_type: TIMESTAMP
      mode: NULLABLE
      description: "Day end timestamp (Local)"
      transform: "string_to_timestamp"

    - name: calendarDate
      json_path: "$.date"
      bq_type: DATE
      mode: REQUIRED
      description: "Date for partitioning"
      transform: "string_to_date"
      validations:
        - type: not_null

    # =========================================================================
    # FLOOR INTERVALS (REPEATED RECORD with array_index)
    # =========================================================================
    - name: floorIntervals
      bq_type: RECORD
      mode: REPEATED
      json_path: "$.floorValuesArray"
      description: "15-minute floor intervals (96 per day)"
      fields:
        - name: startTimeGMT
          array_index: 0
          bq_type: TIMESTAMP
          mode: NULLABLE
          description: "Interval start time"
          transform: "string_to_timestamp"

        - name: endTimeGMT
          array_index: 1
          bq_type: TIMESTAMP
          mode: NULLABLE
          description: "Interval end time"
          transform: "string_to_timestamp"

        - name: floorsAscended
          array_index: 2
          bq_type: INT64
          mode: NULLABLE
          description: "Floors climbed in interval"

        - name: floorsDescended
          array_index: 3
          bq_type: INT64
          mode: NULLABLE
          description: "Floors descended in interval"

metadata_fields:
  - name: raw_data
    bq_type: JSON
    mode: NULLABLE
    description: "Original interval data"

  - name: dp_inserted_at
    bq_type: TIMESTAMP
    mode: REQUIRED
    description: "Ingestion timestamp"
    default: "CURRENT_TIMESTAMP"

  - name: source_file
    bq_type: STRING
    mode: NULLABLE
    description: "Source file for audit"

quality_checks:
  unique_key: calendarDate
  deduplication_strategy: "keep_latest"
  required_fields:
    - calendarDate
  validation_mode: "warn"
  null_handling:
    strategy: "allow"
    replacement_values: {}

transformations:
  string_to_timestamp:
    description: "Convert ISO string to TIMESTAMP"
    logic: "datetime.fromisoformat(value.replace('.0', ''))"

  string_to_date:
    description: "Extract date from ISO string"
    logic: "datetime.fromisoformat(value.replace('.0', '')).date()"

performance:
  batch_size: 500
  max_workers: 4

logging:
  level: INFO
  console: true

notes: |
  REPEATED RECORD WITH ARRAY_INDEX

  This dataset uses REPEATED RECORD with array_index to handle time-series arrays.

  Format:
  - 1 record per day
  - floor_intervals: REPEATED RECORD with 96 elements (15-min intervals)
  - Each element is extracted from sub-array using array_index

  Input array element: ["2025-10-27T08:15:00.0", "2025-10-27T08:30:00.0", 6, 0]

  Mapped using array_index:
  - index 0 → start_time
  - index 1 → end_time
  - index 2 → floors_ascended (6)
  - index 3 → floors_descended (0)

  Result: 1 JSONL line → 1 BigQuery record with 96 nested intervals

  Query example:
  SELECT calendar_date, interval.start_time, interval.floors_ascended
  FROM table, UNNEST(floor_intervals) AS interval
  WHERE interval.floors_ascended > 0

examples:
  - name: "Ingest floors to dev"
    command: "python -m src.connectors.garmin.garmin_ingest_v2 --config floors --env dev"

  - name: "Dry run"
    command: "python -m src.connectors.garmin.garmin_ingest_v2 --config floors --env dev --dry-run"

# =============================================================================
# ALERTING
# =============================================================================
alerting:
  enabled: false
  conditions:
    - name: high_rejection_rate
      threshold: 0.1
    - name: no_data
      threshold: 0
    - name: processing_time
      threshold: 600
  channels:
    - email
    - slack

# =============================================================================
# EXAMPLES
# =============================================================================
examples:
  - name: "Ingest floors to dev"
    command: "python -m src.connectors.garmin.garmin_ingest_v2 --config floors --env dev"
  
  - name: "Ingest floors to prod"
    command: "python -m src.connectors.garmin.garmin_ingest_v2 --config floors --env prd"
  
  - name: "Dry run"
    command: "python -m src.connectors.garmin.garmin_ingest_v2 --config floors --env dev --dry-run"
