# Mode OpÃ©ratoire : Transformation des Nested Arrays dans Garmin Fetcher

## ğŸ¯ Objectif
Transformer automatiquement les nested arrays (`[[a,b]]`) en objets (`[{x:a, y:b}]`) directement dans le connector Garmin pour garantir la compatibilitÃ© BigQuery native.

---

## ğŸ“Š Analyse de la Situation

### Fichiers concernÃ©s (identifiÃ©s lors des tests)
```
body_battery       â†’ bodyBatteryValuesArray: [[timestamp, value]]
heart_rate         â†’ heartRateValues: [[timestamp, value]]
stress             â†’ stressValuesArray: [[timestamp, "MEASURED", value, score]]
stress             â†’ bodyBatteryValuesArray: [[timestamp, value]]
floors             â†’ floorValuesArray: [[timestamp, value]]
intensity_minutes  â†’ (champ inconnu): [[timestamp, value]]
respiration        â†’ respirationValuesArray: [[timestamp, value]]
respiration        â†’ respirationAveragesValuesArray: [[ts, avg, high, low]]
spo2               â†’ (champ inconnu): [[timestamp, value]]
```

### Patterns observÃ©s
1. **Cas gÃ©nÃ©ral (80%)** : `[[timestamp, value]]` â†’ 2 Ã©lÃ©ments
2. **Cas spÃ©ciaux** : 
   - `stressValuesArray`: 4 Ã©lÃ©ments `[timestamp, type, value, score]`
   - `respirationAveragesValuesArray`: 4 Ã©lÃ©ments `[timestamp, average, high, low]`

### StratÃ©gie de dÃ©tection
- âœ… **DÃ©tection structurelle** : Parcourir rÃ©cursivement tout le JSON
- âœ… **Cas spÃ©ciaux** : Dictionnaire de mappings explicites
- âœ… **Fallback gÃ©nÃ©rique** : Si 2 Ã©lÃ©ments â†’ `{timestamp, value}`
- âš ï¸ **Alerte** : Si >2 Ã©lÃ©ments et pas de mapping â†’ logger un warning

---

## ğŸ—ï¸ Architecture de la Solution

### 1. CrÃ©er la fonction de transformation dans `utils.py`

**Fichier** : `src/connectors/garmin/utils.py`

La fonction doit :
- ÃŠtre **rÃ©cursive** pour gÃ©rer les nested objects arbitraires
- Utiliser un **dictionnaire de mappings** pour les cas connus
- Avoir un **fallback gÃ©nÃ©rique** pour les cas simples
- **Logger les warnings** pour les nested arrays non mappÃ©s

### 2. Appliquer la transformation dans `fetcher.py`

**Point d'injection** : Juste avant l'Ã©criture du JSONL

Modifier ces mÃ©thodes :
- `_fetch_daily()` : ligne 91-93
- `_fetch_range()` : ligne 138-142
- `_fetch_simple()` : ligne 164-170
- `_fetch_activity_details()` : ligne 202-207
- `_fetch_activity_subdata()` : ligne 262, 272-275

### 3. Tests de validation

- IngÃ©rer tous les fichiers de test `2025_11_22_*`
- VÃ©rifier que BigQuery accepte tous les fichiers
- Comparer les schÃ©mas auto-dÃ©tectÃ©s

---

## ğŸ’» ImplÃ©mentation Ã‰tape par Ã‰tape

### Ã‰TAPE 1 : Ajouter la fonction de transformation dans `utils.py`

**Code Ã  ajouter** Ã  la fin de `src/connectors/garmin/utils.py` :

```python
def flatten_nested_arrays(
    obj: Any, 
    known_mappings: Dict[str, List[str]] = None,
    path: str = ""
) -> Any:
    """
    Transforme rÃ©cursivement les nested arrays pour compatibilitÃ© BigQuery.
    
    BigQuery ne supporte pas les nested arrays ([[a,b]]).
    Cette fonction les transforme en tableaux d'objets ([{x:a, y:b}]).
    
    Args:
        obj: Objet Ã  transformer (dict, list, ou primitive)
        known_mappings: Mappings explicites pour les cas spÃ©ciaux
            Format: {"field_name": ["key1", "key2", ...]}
        path: Chemin actuel dans l'objet (pour logging)
    
    Returns:
        Objet transformÃ© avec nested arrays aplatis
    
    Examples:
        >>> flatten_nested_arrays([[1, 2], [3, 4]])
        [{'timestamp': 1, 'value': 2}, {'timestamp': 3, 'value': 4}]
        
        >>> flatten_nested_arrays(
        ...     {"data": [[100, "MEASURED", 42, 3.0]]},
        ...     {"data": ["timestamp", "type", "value", "score"]}
        ... )
        {'data': [{'timestamp': 100, 'type': 'MEASURED', 'value': 42, 'score': 3.0}]}
    """
    # Mappings par dÃ©faut (cas connus de Garmin)
    if known_mappings is None:
        known_mappings = {
            'stressValuesArray': ['timestamp', 'type', 'value', 'score'],
            'respirationAveragesValuesArray': ['timestamp', 'average', 'high', 'low'],
            # Fallback : bodyBatteryValuesArray, heartRateValues, etc. sont gÃ©rÃ©s par le cas gÃ©nÃ©rique
        }
    
    # Cas 1 : Dict â†’ rÃ©cursion sur chaque clÃ©
    if isinstance(obj, dict):
        result = {}
        for key, value in obj.items():
            # VÃ©rifier si cette clÃ© est un cas spÃ©cial connu
            if key in known_mappings and isinstance(value, list) and value and isinstance(value[0], list):
                field_names = known_mappings[key]
                result[key] = [
                    dict(zip(field_names, item[:len(field_names)])) 
                    for item in value
                ]
                logging.debug(f"Transformed nested array at '{path}.{key}' using mapping: {field_names}")
            else:
                result[key] = flatten_nested_arrays(value, known_mappings, f"{path}.{key}")
        return result
    
    # Cas 2 : List â†’ vÃ©rifier si c'est un nested array
    elif isinstance(obj, list):
        if not obj:
            return obj
        
        # Nested array dÃ©tectÃ© : [[...], [...]]
        if isinstance(obj[0], list):
            first_item_length = len(obj[0])
            
            # Cas 2a : Longueur 2 â†’ fallback gÃ©nÃ©rique (timestamp, value)
            if first_item_length == 2:
                result = [{'timestamp': item[0], 'value': item[1]} for item in obj]
                logging.debug(f"Transformed generic 2-element nested array at '{path}'")
                return result
            
            # Cas 2b : Longueur > 2 â†’ WARNING (devrait avoir un mapping explicite)
            else:
                logging.warning(
                    f"âš ï¸ Nested array with {first_item_length} elements found at '{path}' "
                    f"without explicit mapping. Consider adding to known_mappings. "
                    f"Using generic keys: val_0, val_1, ..."
                )
                result = [
                    {f'val_{i}': val for i, val in enumerate(item)}
                    for item in obj
                ]
                return result
        
        # Pas un nested array â†’ rÃ©cursion sur chaque Ã©lÃ©ment
        else:
            return [flatten_nested_arrays(item, known_mappings, f"{path}[{i}]") for i, item in enumerate(obj)]
    
    # Cas 3 : Primitive (str, int, float, bool, None) â†’ retour direct
    else:
        return obj
```

### Ã‰TAPE 2 : Modifier `fetcher.py` pour appliquer la transformation

**Import Ã  ajouter** en haut de `src/connectors/garmin/fetcher.py` :

```python
from .utils import flatten_nested_arrays  # Ajouter aprÃ¨s la ligne 11
```

**Modifications Ã  faire** dans chaque mÃ©thode de fetch :

#### 2.1 Dans `_fetch_daily()` (lignes 83-98)

**Remplacer** :
```python
if data:
    # Normalize data structure
    if isinstance(data, list):
        for item in data:
            if isinstance(item, dict):
                item["date"] = date_str
                item["data_type"] = metric_name
                results.append(item)
    elif isinstance(data, dict):
        data["date"] = date_str
        data["data_type"] = metric_name
        results.append(data)
    else:
        results.append({
            "date": date_str, 
            "data": data, 
            "data_type": = metric_name
        })
```

**Par** :
```python
if data:
    # Transform nested arrays first
    data = flatten_nested_arrays(data, path=f"{metric_name}.{date_str}")
    
    # Normalize data structure
    if isinstance(data, list):
        for item in data:
            if isinstance(item, dict):
                item["date"] = date_str
                item["data_type"] = metric_name
                results.append(item)
    elif isinstance(data, dict):
        data["date"] = date_str
        data["data_type"] = metric_name
        results.append(data)
    else:
        results.append({
            "date": date_str, 
            "data": data, 
            "data_type": metric_name
        })
```

#### 2.2 Dans `_fetch_range()` (lignes 134-144)

**Remplacer** :
```python
if not data:
    return []
    
results = []
if isinstance(data, list):
    for item in data:
        if isinstance(item, dict):
            item["data_type"] = metric_name
        results.append(item)
elif isinstance(data, dict):
    data["data_type"] = metric_name
    results.append(data)
else:
    results.append({"data": data, "data_type": metric_name})
```

**Par** :
```python
if not data:
    return []

# Transform nested arrays
data = flatten_nested_arrays(data, path=metric_name)
    
results = []
if isinstance(data, list):
    for item in data:
        if isinstance(item, dict):
            item["data_type"] = metric_name
        results.append(item)
elif isinstance(data, dict):
    data["data_type"] = metric_name
    results.append(data)
else:
    results.append({"data": data, "data_type": metric_name})
```

#### 2.3 Dans `_fetch_simple()` (lignes 160-172)

**Remplacer** :
```python
if not data:
    return []
    
results = []
if isinstance(data, list):
    for item in data:
        if isinstance(item, dict):
            item["data_type"] = metric_name
        results.append(item)
else:
    # If it's a dict or primitive
    if isinstance(data, dict):
        data["data_type"] = metric_name
        results.append(data)
    else:
        results.append({"data": data, "data_type": metric_name})
```

**Par** :
```python
if not data:
    return []

# Transform nested arrays
data = flatten_nested_arrays(data, path=metric_name)
    
results = []
if isinstance(data, list):
    for item in data:
        if isinstance(item, dict):
            item["data_type"] = metric_name
        results.append(item)
else:
    # If it's a dict or primitive
    if isinstance(data, dict):
        data["data_type"] = metric_name
        results.append(data)
    else:
        results.append({"data": data, "data_type": metric_name})
```

#### 2.4 Dans `_fetch_activity_details()` (lignes 200-211)

**Remplacer** :
```python
try:
    details = client.get_activity_details(activity_id, maxchart=2000, maxpoly=4000)
    enriched = {
        **activity,
        "detailed_data": details,
        "data_type": "activity_details"
    }
    results.append(enriched)
    time.sleep(0.5)
except Exception as e:
    logging.warning(f"Failed details for {activity_id}: {e}")
```

**Par** :
```python
try:
    details = client.get_activity_details(activity_id, maxchart=2000, maxpoly=4000)
    
    # Transform nested arrays in activity and details
    clean_activity = flatten_nested_arrays(activity, path=f"activity_{activity_id}")
    clean_details = flatten_nested_arrays(details, path=f"details_{activity_id}")
    
    enriched = {
        **clean_activity,
        "detailed_data": clean_details,
        "data_type": "activity_details"
    }
    results.append(enriched)
    time.sleep(0.5)
except Exception as e:
    logging.warning(f"Failed details for {activity_id}: {e}")
```

#### 2.5 Dans `_fetch_activity_subdata()` (lignes 241-288)

**Pour le cas `activity_splits`** (lignes 242-262), remplacer :
```python
splits = client.get_activity_splits(activity_id)
typed_splits = client.get_activity_typed_splits(activity_id)
split_summaries = client.get_activity_split_summaries(activity_id)

data = {
    "activityId": activity_id,
    "activityName": activity.get("activityName", ""),
    "activityType": activity.get("activityType", ""),
    "startTimeLocal": activity.get("startTimeLocal", ""),
    "splits": splits,
    "typed_splits": typed_splits,
    "split_summaries": split_summaries,
    "data_type": metric_name
}
```

**Par** :
```python
splits = client.get_activity_splits(activity_id)
typed_splits = client.get_activity_typed_splits(activity_id)
split_summaries = client.get_activity_split_summaries(activity_id)

# Transform nested arrays
clean_splits = flatten_nested_arrays(splits, path=f"splits_{activity_id}")
clean_typed = flatten_nested_arrays(typed_splits, path=f"typed_splits_{activity_id}")
clean_summaries = flatten_nested_arrays(split_summaries, path=f"summaries_{activity_id}")

data = {
    "activityId": activity_id,
    "activityName": activity.get("activityName", ""),
    "activityType": activity.get("activityType", ""),
    "startTimeLocal": activity.get("startTimeLocal", ""),
    "splits": clean_splits,
    "typed_splits": clean_typed,
    "split_summaries": clean_summaries,
    "data_type": metric_name
}
```

**Pour les autres cas** (lignes 264-285), remplacer :
```python
# Standard subdata (weather, hr_zones, etc)
subdata = method(activity_id)
if subdata:
    data = {
        "activityId": activity_id,
        "activityName": activity.get("activityName", ""),
        "activityType": activity.get("activityType", ""),
        "startTimeLocal": activity.get("startTimeLocal", ""),
        f"{metric_name}_data": subdata,
        "data_type": metric_name
    }
```

**Par** :
```python
# Standard subdata (weather, hr_zones, etc)
subdata = method(activity_id)
if subdata:
    # Transform nested arrays
    clean_subdata = flatten_nested_arrays(subdata, path=f"{metric_name}_{activity_id}")
    
    data = {
        "activityId": activity_id,
        "activityName": activity.get("activityName", ""),
        "activityType": activity.get("activityType", ""),
        "startTimeLocal": activity.get("startTimeLocal", ""),
        f"{metric_name}_data": clean_subdata,
        "data_type": metric_name
    }
```

---

## âœ… Tests de Validation

### 1. Test unitaire de la fonction

CrÃ©er `test_flatten_nested_arrays.py` :

```python
from src.connectors.garmin.utils import flatten_nested_arrays

def test_simple_2_element():
    input_data = [[1000, 42], [2000, 43]]
    expected = [{'timestamp': 1000, 'value': 42}, {'timestamp': 2000, 'value': 43}]
    assert flatten_nested_arrays(input_data) == expected

def test_stress_values_4_element():
    input_data = {
        'stressValuesArray': [[1000, "MEASURED", 42, 3.0], [2000, "MEASURED", 43, 3.1]]
    }
    expected = {
        'stressValuesArray': [
            {'timestamp': 1000, 'type': 'MEASURED', 'value': 42, 'score': 3.0},
            {'timestamp': 2000, 'type': 'MEASURED', 'value': 43, 'score': 3.1}
        ]
    }
    assert flatten_nested_arrays(input_data) == expected

def test_nested_objects():
    input_data = {
        'activity': {
            'heartRate': [[1000, 120], [2000, 125]]
        }
    }
    expected = {
        'activity': {
            'heartRate': [
                {'timestamp': 1000, 'value': 120},
                {'timestamp': 2000, 'value': 125}
            ]
        }
    }
    assert flatten_nested_arrays(input_data) == expected
```

### 2. Test d'intÃ©gration (ingestion BigQuery)

```bash
# 1. Fetch fresh data avec transformation
python -m src.connectors.garmin --start-date 2025-11-22 --end-date 2025-11-22

# 2. VÃ©rifier que les fichiers sont crÃ©Ã©s
ls -la *.jsonl

# 3. Tester l'ingestion
python test_ingestion.py

# 4. VÃ©rifier qu'il n'y a AUCUNE erreur "Nested arrays not allowed"
```

### 3. Tests de rÃ©gression

Comparer avec les anciens fichiers :
- Nombre de lignes identique
- Champs principaux prÃ©sents
- Pas de perte de donnÃ©es (seulement transformation de structure)

---

## ğŸš¨ Points d'Attention

### 1. DÃ©tection de nouveaux cas
Si Garmin ajoute un nouveau champ avec nested array >2 Ã©lÃ©ments :
- âœ… Le warning sera loggÃ©
- âœ… La transformation gÃ©nÃ©rique `val_0, val_1` s'applique
- âš ï¸ Ã€ terme, ajouter le mapping explicite dans `known_mappings`

### 2. Performance
La fonction est rÃ©cursive â†’ peut Ãªtre lente sur de trÃ¨s gros objets.
- âœ”ï¸ OK pour Garmin (objets modÃ©rÃ©s, <1MB par activitÃ©)
- âš ï¸ Si problÃ¨me, envisager une version itÃ©rative

### 3. CompatibilitÃ© backward
Les fichiers existants (dÃ©jÃ  ingÃ©rÃ©s) ne seront **pas** affectÃ©s.
- Les nouvelles ingestions auront le nouveau format
- Pour rÃ©ingÃ©rer l'historique, refaire un fetch complet

---

## ğŸ“ Checklist de DÃ©ploiement

- [ ] Ajouter `flatten_nested_arrays()` dans `utils.py`
- [ ] Importer la fonction dans `fetcher.py`
- [ ] Modifier `_fetch_daily()`
- [ ] Modifier `_fetch_range()`
- [ ] Modifier `_fetch_simple()`
- [ ] Modifier `_fetch_activity_details()`
- [ ] Modifier `_fetch_activity_subdata()` (2 cas)
- [ ] CrÃ©er les tests unitaires
- [ ] Tester sur un petit dataset (1 jour)
- [ ] Tester l'ingestion BigQuery
- [ ] Valider absence d'erreurs
- [ ] DÃ©ployer en production

---

## ğŸ“ RÃ©sumÃ©

**Avant** :
```json
{"heartRate": [[1000, 120], [2000, 125]]}
```

**AprÃ¨s** :
```json
{"heartRate": [
  {"timestamp": 1000, "value": 120},
  {"timestamp": 2000, "value": 125}
]}
```

**RÃ©sultat** : âœ… Compatible BigQuery nativement, âœ… AutodÃ©tection parfaite, âœ… Maintenance = 0
